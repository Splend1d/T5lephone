{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adcdf425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT! ADJUST PARAMETERS ACCORDING TO MODEL\n",
    "\n",
    "_max_input = 1024\n",
    "# byte models : 1024, word models : 512\n",
    "_max_output = 128\n",
    "# byte models : 128, word models : 16\n",
    "splt = \"validation\"\n",
    "# \"validation\" or \"test\"\n",
    "asr_system = \"wav2vec2-large-960h-lv60-self\"\n",
    "# \"wav2vec2-large-960h-lv60-self\" or \"wav2vec2-large-10min-lv60-self\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fbe793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_eos_to_examples(example):\n",
    "    example['input_text'] = 'question: %s  context: %s </s>'% (example['question_asr'].lower(), example['context_asr'].lower())\n",
    "    example['target_text'] = '%s </s>' % example['answers']['text'][0]\n",
    "    \n",
    "    return example\n",
    "\n",
    "# tokenize the examples\n",
    "def convert_to_features(example_batch):\n",
    "    input_encodings = tokenizer.batch_encode_plus(example_batch['input_text'], padding='max_length', truncation=True, max_length=_max_input)\n",
    "    target_encodings = tokenizer.batch_encode_plus(example_batch['target_text'], padding='max_length', truncation=True, max_length=_max_output)\n",
    "\n",
    "    encodings = {\n",
    "        'input_ids': input_encodings['input_ids'], \n",
    "        'attention_mask': input_encodings['attention_mask'],\n",
    "        'target_ids': target_encodings['input_ids'],\n",
    "        'target_attention_mask': target_encodings['attention_mask']\n",
    "    }\n",
    "\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23894166",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SQuAD evaluation script. Modifed slightly for this notebook\n",
    "\n",
    "from __future__ import print_function\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    #print(prediction,ground_truth)\n",
    "    prediction_tokens = normalize_answer(prediction).split()\n",
    "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
    "    \n",
    "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    #print(prediction,ground_truth,prediction_tokens,ground_truth_tokens,num_same)\n",
    "    #s()\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(prediction_tokens)\n",
    "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
    "    \n",
    "    if precision > 1.0 or recall > 1.0:\n",
    "      print(prediction,ground_truth)\n",
    "      s()\n",
    "    \n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    #print(f1)\n",
    "    return f1\n",
    "\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    # since prediction != ground truth, use time span\n",
    "    if normalize_answer(prediction) == normalize_answer(ground_truth):\n",
    "      return 1\n",
    "    else:\n",
    "      return 0\n",
    "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "\n",
    "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
    "    scores_for_ground_truths = []\n",
    "    for ground_truth in ground_truths:\n",
    "        score = metric_fn(prediction, ground_truth)\n",
    "        scores_for_ground_truths.append(score)\n",
    "    return max(scores_for_ground_truths)\n",
    "\n",
    "\n",
    "def evaluate(gold_answers, predictions,references_time = None,predictions_time = None):\n",
    "    f1 = exact_match = total = 0\n",
    "    tot_ff1 = tot_aos = 0\n",
    "    idx = 0\n",
    "    for ground_truths, prediction in zip(gold_answers, predictions):\n",
    "      #print(ground_truths,prediction)\n",
    "      is_exact_match = metric_max_over_ground_truths(\n",
    "                    exact_match_score, prediction, ground_truths)\n",
    "      \n",
    "      \n",
    "      #print(\"after exact\",ground_truths,prediction)\n",
    "      #s()\n",
    "      f1 += metric_max_over_ground_truths(\n",
    "          f1_score, prediction, ground_truths)\n",
    "      #print(f1/total)\n",
    "      \n",
    "      if references_time and predictions_time:\n",
    "        if is_exact_match:\n",
    "          maxff1 = 1\n",
    "          maxAOS = 1\n",
    "        else:\n",
    "          refs = references_time[total]\n",
    "          preds = predictions_time[total]\n",
    "          maxAOS = 0\n",
    "          maxff1 = 0\n",
    "          maxprecision = 0\n",
    "          maxrecall = 0\n",
    "          for r in refs:\n",
    "            for p in preds:\n",
    "              prev_start, ans_start, ans_end, next_end = p\n",
    "              #print(ans_start,ans_end,r[0],r[1])\n",
    "              overlap = [max(r[0],ans_start),min(r[1],ans_end)]\n",
    "              overlap_delta = max((overlap[1] - overlap[0]),0)\n",
    "              union = [min(r[0],ans_start),max(r[1],ans_end)]\n",
    "              union_delta = union[1] - union[0]\n",
    "              #print(overlap_delta,union_delta)\n",
    "              AOS = overlap_delta/union_delta\n",
    "              maxAOS = max(AOS,maxAOS)\n",
    "\n",
    "              x_delta = ans_end - ans_start\n",
    "              y_delta = r[1] - r[0]\n",
    "              precision = overlap_delta/x_delta\n",
    "              recall = overlap_delta/y_delta\n",
    "              \n",
    "              maxprecision = max(maxprecision,precision)\n",
    "              maxrecall = max(maxrecall,recall)\n",
    "\n",
    "              # check shift_right_AOS\n",
    "              #print(ans_start,next_end,r[0],r[1])\n",
    "              overlap = [max(r[0],ans_start),min(r[1],next_end)]\n",
    "              overlap_delta = max((overlap[1] - overlap[0]),0)\n",
    "              union = [min(r[0],ans_start),max(r[1],next_end)]\n",
    "              union_delta = union[1] - union[0]\n",
    "              #print(overlap_delta,union_delta)\n",
    "              shiftright_AOS = overlap_delta/union_delta\n",
    "              \n",
    "              # check shift_left_AOS\n",
    "              #print(prev_start,ans_end,r[0],r[1])\n",
    "              overlap = [max(r[0],prev_start),min(r[1],ans_end)]\n",
    "              overlap_delta = max((overlap[1] - overlap[0]),0)\n",
    "              union = [min(r[0],prev_start),max(r[1],ans_end)]\n",
    "              union_delta = union[1] - union[0]\n",
    "              shiftleft_AOS = overlap_delta/union_delta\n",
    "              #print(AOS,shiftright_AOS, shiftleft_AOS)\n",
    "              \n",
    "              if AOS > shiftright_AOS and AOS > shiftleft_AOS:\n",
    "                pass\n",
    "                #AOS = 1\n",
    "                #maxAOS = max(AOS,maxAOS)\n",
    "                #maxprecision = 1\n",
    "                #maxrecall = 1\n",
    "                #maxff1 = 1\n",
    "                #is_exact_match = 1\n",
    "                break\n",
    "            if is_exact_match:\n",
    "              break\n",
    "              \n",
    "\n",
    "            try:\n",
    "              maxff1 = 2*maxprecision*maxrecall/(maxprecision+maxrecall)\n",
    "            except:\n",
    "              maxff1 = 0\n",
    "        tot_ff1 += maxff1\n",
    "        tot_aos += maxAOS\n",
    "      exact_match += is_exact_match\n",
    "      total += 1\n",
    "    \n",
    "    exact_match = 100.0 * exact_match / total\n",
    "    f1 = 100.0 * f1 / total\n",
    "    aos = 100.0*tot_aos/total\n",
    "    ff1 = 100.0 * tot_ff1 / total\n",
    "\n",
    "    return {'exact_match': exact_match, 'f1': f1, \"ff1\":ff1, \"aos\":aos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ca239",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/huggingface/transformers.git\n",
    "!pip install -q ./transformers\n",
    "!pip install -q -U nlp\n",
    "!pip install -q tpubar sentencepiece\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2318bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datasets\n",
    "from transformers import T5ForConditionalGeneration, ByT5Tokenizer,T5Tokenizer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d438323c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcb966962514d988da94ed4c0efdf70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/816 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28eee4028d6d427ab50505bffc500b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model = T5ForConditionalGeneration.from_pretrained('Splend1dchan/t5-small-squad').to('cuda')\n",
    "#model = T5ForConditionalGeneration.from_pretrained('valhalla/t5-base-squad').to('cuda')\n",
    "#model = T5ForConditionalGeneration.from_pretrained('Splend1dchan/t5-large-squad').to('cuda')\n",
    "\n",
    "#model = T5ForConditionalGeneration.from_pretrained('Splend1dchan/byt5small-squad1024-from6000steps').to('cuda')\n",
    "#model = T5ForConditionalGeneration.from_pretrained('Splend1dchan/byt5-base-squad').to('cuda') \n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('Splend1dchan/t5lephone-small-textsquad').to('cuda') # ByT5Tokenizer\n",
    "\n",
    "#tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "tokenizer = ByT5Tokenizer.from_pretrained('google/byt5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54572c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Splend1dchan--NMSQA_wav2vec2-large-960h-lv60-self-331c7554e52616ed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset parquet/Splend1dchan--NMSQA_wav2vec2-large-960h-lv60-self to /home/splend1d/.cache/huggingface/datasets/parquet/Splend1dchan--NMSQA_wav2vec2-large-960h-lv60-self-331c7554e52616ed/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7e5f0212504fb09a5e725969062336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a140111a2a5f4716bbf72e953f8fe4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/668k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f9002dfefa41b8bae936f665ae063d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/8.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1eec26dc1154915baf6fca856bf3f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/splend1d/.cache/huggingface/datasets/parquet/Splend1dchan--NMSQA_wav2vec2-large-960h-lv60-self-331c7554e52616ed/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28053194e55c4b6da890a4da82bbf589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05bbebd668941eaadb1658bf2bac3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/splend1d/.local/lib/python3.7/site-packages/transformers/models/byt5/tokenization_byt5.py:150: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated\"\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = datasets.load_dataset(f'Splend1dchan/NMSQA_{asr_system}', split=splt)\n",
    "valid_dataset = valid_dataset.map(add_eos_to_examples, load_from_cache_file=False)\n",
    "valid_dataset = valid_dataset.map(convert_to_features, batched=True, load_from_cache_file=False)\n",
    "\n",
    "\n",
    "# set the tensor type and the columns which the dataset should return\n",
    "columns = ['input_ids', 'target_ids', 'attention_mask', 'target_attention_mask']\n",
    "valid_dataset.set_format(type='torch', columns=columns)\n",
    "dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06724477",
   "metadata": {},
   "source": [
    "# Generate Text Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e59055ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653b51b5e8e14efab0a871076c8a1de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5247 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>denver broncos </s>', '<pad>denver broncos </s>']\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for n,batch in tqdm(enumerate(dataloader), total = len(dataloader)):\n",
    "  outs = model.generate(input_ids=batch['input_ids'].cuda(), \n",
    "                        attention_mask=batch['attention_mask'].cuda(),\n",
    "                        max_length=_max_output,\n",
    "                        )\n",
    "  outs = [tokenizer.decode(ids) for ids in outs]\n",
    "  answers.extend(outs)\n",
    "  if n == 0:\n",
    "    print(outs)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85bba76",
   "metadata": {},
   "source": [
    "# Find timespan from text answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bcacb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Splend1dchan--NMSQA_wav2vec2-large-960h-lv60-self-331c7554e52616ed\n",
      "Reusing dataset parquet (/home/splend1d/.cache/huggingface/datasets/parquet/Splend1dchan--NMSQA_wav2vec2-large-960h-lv60-self-331c7554e52616ed/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    }
   ],
   "source": [
    "valid_word_dataset = datasets.load_dataset(f'Splend1dchan/NMSQA_{asr_system}', split=splt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "871a4d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(string1, string2):\n",
    "    \"\"\"Ref: https://bit.ly/2Pf4a6Z\"\"\"\n",
    "    if len(string2) < len(string1):\n",
    "      string1, string2 = string2, string1\n",
    "    if len(string1) > len(string2):\n",
    "        difference = len(string1) - len(string2)\n",
    "        string1[:difference]\n",
    "\n",
    "    elif len(string2) > len(string1):\n",
    "        difference = len(string2) - len(string1)\n",
    "        string2[:difference]\n",
    "\n",
    "    else:\n",
    "        difference = 0\n",
    "\n",
    "    for i in range(len(string1)):\n",
    "        if string1[i] != string2[i]:\n",
    "            difference += 1\n",
    "\n",
    "    return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c52be07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d064ed384bb4b0abafcf05fe84af392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10493 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no ans: 656\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "predictions_times = []\n",
    "references = []\n",
    "references_times = []\n",
    "not_extractive = 0\n",
    "for ref, pred in tqdm(zip(valid_word_dataset, answers),total = len(valid_word_dataset)):\n",
    "  context_wrd_ls = ref[\"context_asr\"].lower().split()\n",
    "  question_wrd_ls = ref[\"question_asr\"].lower().split()\n",
    "  pred_wrd_ls = pred.replace(\"<pad>\",\"\").replace(\"</s>\",\"\").split()\n",
    "  \n",
    "  l = len(pred_wrd_ls)\n",
    "  found = False\n",
    "  predictions_time = []\n",
    "  found = False\n",
    "  for i in range(len(context_wrd_ls)):\n",
    "    if context_wrd_ls[i:i+l] == pred_wrd_ls[:]:\n",
    "      start_idx = i\n",
    "      end_idx = i + l - 1\n",
    "      timespan = [ref[\"context_times\"][start_idx][0],ref[\"context_times\"][end_idx][1]]\n",
    "      if start_idx != 0:\n",
    "        timespan = [ref[\"context_times\"][start_idx-1][0]] + timespan\n",
    "      else:\n",
    "        timespan = [ref[\"context_times\"][start_idx][0]] + timespan\n",
    "      \n",
    "      if end_idx != len(ref[\"context_times\"]) - 1:\n",
    "        timespan =  timespan + [ref[\"context_times\"][end_idx+1][0]]\n",
    "      else:\n",
    "        timespan = timespan + [ref[\"context_times\"][end_idx][0]]\n",
    "      predictions_time.append(timespan)\n",
    "      found = True\n",
    "  if not found:\n",
    "    #print(context_wrd_ls,pred_wrd_ls)\n",
    "    min_e = len(context_wrd_ls) * 2\n",
    "    for i in range(len(context_wrd_ls)-l):\n",
    "      context =  \" \".join(context_wrd_ls[i:i+l])\n",
    "      pred = \" \".join(pred_wrd_ls[:])\n",
    "      e = edit_distance(context,pred)\n",
    "      if e < min_e:\n",
    "        min_e = e\n",
    "        start_idx = i\n",
    "        end_idx = i + l - 1\n",
    "    #print(start_idx,end_idx)\n",
    "    try:\n",
    "      timespan = [ref[\"context_times\"][start_idx][0],ref[\"context_times\"][end_idx][1]]\n",
    "      if start_idx != 0:\n",
    "        timespan = [ref[\"context_times\"][start_idx-1][0]] + timespan\n",
    "      else:\n",
    "        timespan = [ref[\"context_times\"][start_idx][0]] + timespan\n",
    "      \n",
    "      if end_idx != len(ref[\"context_times\"]) - 1:\n",
    "        timespan =  timespan + [ref[\"context_times\"][end_idx+1][0]]\n",
    "      else:\n",
    "        timespan = timespan + [ref[\"context_times\"][end_idx][0]]\n",
    "      predictions_time.append(timespan)\n",
    "    except:\n",
    "      predictions_time.append([0,0,10,10])\n",
    "\n",
    "\n",
    "    not_extractive += 1\n",
    "  predictions_times.append(predictions_time)\n",
    "  references_time = []\n",
    "  for s, e in zip(ref[\"answers\"][\"audio_full_answer_start\"],ref[\"answers\"][\"audio_full_answer_end\"]):\n",
    "    references_time.append([s,e])\n",
    "  references_times.append(references_time)\n",
    "  #break\n",
    "  predictions.append(pred.replace(\"<pad>\",\"\").replace(\"</s>\",\"\"))\n",
    "  references.append(ref[\"answers\"][\"text\"])\n",
    "  #references_time.append(ref[\"answers\"][\"text\"][0])\n",
    "print(\"no ans:\",not_extractive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87d2c96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "denver broncos  ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'] [[9.896, 10.336, 11.116, 11.196]] [[10.29, 11.15]]\n",
      "denver broncos  ['Carolina Panthers', 'Carolina Panthers', 'Carolina Panthers'] [[9.896, 10.336, 11.116, 11.196]] [[14.64, 15.559999999999999]]\n",
      "levi stadium in the san francisco bay area at santa clara california  ['Santa Clara, California', \"Levi's Stadium\", \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"] [[21.296, 21.416, 25.156, 25.496]] [[24.02403628117914, 25.32403628117914], [21.43403628117914, 22.27403628117914], [21.43403628117914, 25.32403628117914]]\n",
      "denver broncos  ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'] [[9.896, 10.336, 11.116, 11.196]] [[10.29, 11.15]]\n",
      "gold  ['gold', 'gold', 'gold'] [[29.576, 29.976, 30.156, 30.195999999999998]] [[28.448072562358277, 28.77807256235828]]\n",
      "arabic numerals  ['\"golden anniversary\"', 'gold-themed', '\"golden anniversary'] [[40.756, 40.896, 41.635999999999996, 41.716]] [[28.448072562358277, 29.378072562358277], [29.998072562358278, 30.478072562358278], [28.448072562358277, 29.378072562358277]]\n",
      "february seventh twenty sixteen  ['February 7, 2016', 'February 7', 'February 7, 2016'] [[18.936, 19.096, 20.916, 21.296]] [[19.09403628117914, 21.05403628117914], [19.09403628117914, 20.014036281179138]]\n",
      "f c champion carolina panthers twenty four ten  ['American Football Conference', 'American Football Conference', 'American Football Conference'] [[13.396, 13.616, 16.256, 16.356]] [[7.46, 8.92]]\n",
      "arabic numerals  ['\"golden anniversary\"', 'gold-themed', 'gold'] [[40.756, 40.896, 41.635999999999996, 41.716]] [[28.448072562358277, 29.378072562358277], [29.998072562358278, 30.478072562358278], [28.448072562358277, 28.77807256235828]]\n",
      "f c champion denver broncos defeated the national football conference and f c champion carolina panthers twenty four ten  ['American Football Conference', 'American Football Conference', 'American Football Conference'] [[9.136, 9.336, 16.256, 16.356]] [[7.46, 8.92]]\n",
      "february seventh twenty sixteen  ['February 7, 2016', 'February 7', 'February 7, 2016'] [[18.936, 19.096, 20.916, 21.296]] [[19.09403628117914, 21.05403628117914], [19.09403628117914, 20.014036281179138]]\n",
      "the logo could prominently feature the arabic numerals  ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'] [[39.036, 39.196, 41.635999999999996, 41.716]] [[10.29, 11.15]]\n",
      "levi stadium  [\"Levi's Stadium\", \"Levi's Stadium\", \"Levi's Stadium in the San Francisco Bay Area at Santa Clara\"] [[21.296, 21.416, 22.195999999999998, 22.256]] [[21.43403628117914, 22.27403628117914], [21.43403628117914, 24.63403628117914]]\n",
      "san francisco bay  ['Santa Clara', 'Santa Clara', 'Santa Clara'] [[22.355999999999998, 22.496, 23.416, 23.555999999999997]] [[24.02403628117914, 24.63403628117914]]\n",
      "superball fifty  ['Super Bowl L', 'L', 'Super Bowl L'] [[37.635999999999996, 37.775999999999996, 38.536, 38.916]] [[37.778072562358275, 38.45807256235828], [38.33807256235828, 38.45807256235828]]\n",
      "twenty fifteen  ['2015', 'the 2015 season', '2015'] [[5.94, 6.06, 6.66, 6.76]] [[5.99, 6.7], [5.89, 7.1]]\n",
      "2010 ['2015', '2016', '2015'] [[0.24, 0.54, 0.7, 0.78]] [[5.99, 6.7]]\n",
      "san francisco bay  ['Santa Clara', 'Santa Clara', 'Santa Clara'] [[22.355999999999998, 22.496, 23.416, 23.555999999999997]] [[24.02403628117914, 24.63403628117914]]\n",
      "levi stadium  [\"Levi's Stadium\", \"Levi's Stadium\", \"Levi's Stadium\"] [[21.296, 21.416, 22.195999999999998, 22.256]] [[21.43403628117914, 22.27403628117914]]\n",
      "f c champion carolina panthers twenty four ten  ['24–10', '24–10', '24–10'] [[13.396, 13.616, 16.256, 16.356]] [[15.559999999999999, 16.32]]\n",
      "february seventh twenty sixteen  ['February 7, 2016', 'February 7, 2016', 'February 7, 2016'] [[18.936, 19.096, 20.916, 21.296]] [[19.09403628117914, 21.05403628117914]]\n",
      "2007 ['2015', '2016', '2016'] [[0.24, 0.54, 0.7, 0.78]] [[5.99, 6.7]]\n",
      "denver broncos  ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'] [[9.896, 10.336, 11.116, 11.196]] [[10.29, 11.15]]\n",
      "denver broncos  ['Carolina Panthers', 'Carolina Panthers', 'Carolina Panthers'] [[9.896, 10.336, 11.116, 11.196]] [[14.64, 15.559999999999999]]\n",
      "denver broncos  ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'] [[9.896, 10.336, 11.116, 11.196]] [[10.29, 11.15]]\n",
      "twenty fifteen  ['2015', 'the 2015 season', '2015'] [[5.94, 6.06, 6.66, 6.76]] [[5.99, 6.7], [5.89, 7.1]]\n",
      "denver broncos  ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'] [[9.896, 10.336, 11.116, 11.196]] [[10.29, 11.15]]\n",
      "levi stadium in the san francisco bay area at santa clara california  ['Santa Clara, California.', \"Levi's Stadium\", \"Levi's Stadium\"] [[21.296, 21.416, 25.156, 25.496]] [[24.02403628117914, 25.32403628117914], [21.43403628117914, 22.27403628117914]]\n",
      "super boll fifty  ['Super Bowl', 'Super Bowl', 'Super Bowl'] [[0.24, 0.24, 1.0, 1.08]] [[0.1, 0.71]]\n",
      "denver broncos  ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'] [[9.896, 10.336, 11.116, 11.196]] [[10.29, 11.15]]\n",
      "kim newton  ['Cam Newton', 'Cam Newton', 'Cam Newton'] [[4.5, 5.12, 5.62, 5.72]] [[5.07, 5.67]]\n",
      "eight  ['8', 'eight', 'eight'] [[39.519999999999996, 39.839999999999996, 39.98, 40.04]] [[30.952018140589566, 31.47201814058957], [30.952018140589566, 31.47201814058957]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,32):\n",
    "  print(predictions[i], references[i],predictions_times[i],references_times[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd884a70",
   "metadata": {},
   "source": [
    "# evaluate via AOS/FF1 metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3221d56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squad results\n",
      "{'exact_match': 27.961498141618222, 'f1': 45.702214542086516, 'ff1': 64.45928227276359, 'aos': 59.21146849076837}\n"
     ]
    }
   ],
   "source": [
    "if splt == \"validation\":\n",
    "  len_squad = len(references)\n",
    "else:\n",
    "  len_squad = sum([1 for x in valid_word_dataset[\"question_audio_path\"] if \"squad\" in x])\n",
    "print(\"squad results\")\n",
    "res = evaluate(references[:len_squad], predictions[:len_squad],references_times[:len_squad],predictions_times[:len_squad])\n",
    "print(res)\n",
    "if splt == \"test\":\n",
    "    print(\"OOF results\")\n",
    "    res = evaluate(references[len_squad:], predictions[len_squad:],references_times[len_squad:],predictions_times[len_squad:])\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9850df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
